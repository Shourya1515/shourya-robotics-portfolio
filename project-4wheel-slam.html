<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>4-Wheel Autonomous Robot – SLAM & Navigation</title>
  <link rel="stylesheet" href="style.css" />
</head>

<body class="theme-clean anim-medium">

<header class="site-header">
  <div class="logo">Shourya<span>Robotics</span></div>
  <nav>
    <a href="index.html">Home</a>
    <a href="#projects">Projects</a>
  </nav>
</header>

<section class="project-details section reveal">

  <h2 class="section-title">4-Wheel Autonomous Robot with SLAM & Navigation</h2>

  <p>
    This project demonstrates a fully autonomous 4-wheel differential drive robot
    built using <b>ROS2 Foxy</b>, <b>SLAM Toolbox</b>, <b>Nav2 Navigation Stack</b>, and a 
    <b>URDF-based robot model</b>. The robot uses LiDAR for mapping, real-time localization, 
    and path planning to autonomously navigate a multi-room indoor environment.
  </p>

  <h3>Gallery</h3>

  <div class="gallery-grid">
    <img src="images/4wheel/nav1.jpg" alt="RViz robot model">
    <img src="images/4wheel/nav2.jpg" alt="SLAM mapping result">
    <img src="images/4wheel/nav3.jpg" alt="Costmaps and navigation paths">
  </div>

  <h3>Project Overview</h3>
  <p>
    The robot was carefully modeled in URDF with correct physical dimensions, wheel joints,
    and sensor placement. A simulated LiDAR scanner publishes scans used by 
    <b>SLAM Toolbox</b> to generate a highly accurate multi-room 2D occupancy grid map.
  </p>
  <p>
    Once the map is built, <b>Nav2</b> handles global planning (NavFn / Smac Hybrid Planner)
    and local obstacle avoidance using costmaps, enabling the robot to reach any goal point
    in the environment autonomously.
  </p>

  <h3>Technical Breakdown</h3>
  <ul>
    <li><b>URDF Robot Model:</b> Base link, wheel joints, LiDAR frame, collision + visual meshes.</li>
    <li><b>SLAM Toolbox:</b> Real-time mapping with loop closure.</li>
    <li><b>Nav2 Navigation:</b> Global + local planners, behavior tree executor.</li>
    <li><b>Costmap Server:</b> Marking & clearing layers with obstacle inflation.</li>
    <li><b>TF Transform Tree:</b> Proper linking of base_link → laser → odom → map frames.</li>
    <li><b>Odometry:</b> Differential drive odom based on wheel velocities.</li>
    <li><b>RViz Integration:</b> Display of SLAM map, robot pose, costmaps, and path planning.</li>
  </ul>

  <h3>Key Features</h3>
  <ul>
    <li>Complete multi-room SLAM map generation using LiDAR.</li>
    <li>Autonomous navigation with dynamic obstacle avoidance.</li>
    <li>Accurate robot localization using AMCL or SLAM pose estimation.</li>
    <li>Visualization of laser scans, paths, TF tree, and costmaps.</li>
    <li>Modular system easily portable to physical hardware.</li>
  </ul>

  <h3>Outcome</h3>
  <p>
    The robot successfully performed indoor exploration, mapping, and autonomous navigation,
    demonstrating a full robotics pipeline from simulation to autonomy. This project highlights
    expertise in <b>robot modeling, ROS2 navigation, SLAM algorithms, and system integration</b>.
  </p>

  <a href="index.html" class="btn ghost" style="margin-top:20px;">← Back to Projects</a>

</section>

</body>
</html>
