<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>4-Wheel Autonomous Robot – SLAM & Navigation</title>
  <link rel="stylesheet" href="style.css" />
  <script defer src="main.js"></script>
</head>

<body class="theme-clean anim-medium">

  <!-- HEADER -->
  <header class="site-header">
    <div class="logo">Shourya<span>Robotics</span></div>
    <nav>
      <a href="index.html">Home</a>
      <a href="#projects">Projects</a>
    </nav>
  </header>

  <!-- PROJECT WRAPPER -->
  <div class="project-wrapper">

    <h1 class="section-title reveal">4-Wheel Autonomous Robot with SLAM & Navigation</h1>

    <p class="reveal">
      A fully autonomous 4-wheel differential-drive robot built using
      <b>ROS2 Foxy</b>, <b>SLAM Toolbox</b>, <b>Nav2 Navigation Stack</b>, and a complete
      <b>URDF robot model</b>.  
      The robot performs LiDAR-based mapping, localization, and autonomous path planning across a multi-room indoor environment.
    </p>

    <!-- GALLERY -->
    <h3 class="reveal">Gallery</h3>

    <div class="gallery-grid reveal">

      <!-- IMAGE -->
      <img
        src="images/4wheel/nav1.jpg"
        alt="RViz robot model"
        class="gallery-item"
        data-src="images/4wheel/nav1.jpg"
        data-type="image">

      <!-- VIDEO: MAPPING -->
      <video
        class="gallery-item"
        muted
        data-src="images/4wheel/mapping_updated.mp4"
        data-type="video">
        <source src="images/4wheel/mapping_updated.mp4" type="video/mp4">
      </video>

      <!-- VIDEO: NAVIGATION -->
      <video
        class="gallery-item"
        muted
        data-src="images/4wheel/navigation_completed.mp4"
        data-type="video">
        <source src="images/4wheel/navigation_completed.mp4" type="video/mp4">
      </video>

    </div>

    <!-- OVERVIEW -->
    <h3 class="section-title reveal">Project Overview</h3>

    <p class="reveal">
      The robot was modeled in URDF with accurate wheel joints, LiDAR placement, and collision/visual geometry.  
      A simulated LiDAR publishes scans used by <b>SLAM Toolbox</b> to generate a precise multi-room occupancy grid map.
    </p>

    <p class="reveal">
      After mapping, <b>Nav2</b> performs global path planning and local obstacle avoidance using layered costmaps,
      enabling the robot to safely navigate between rooms with continuous feedback from odometry and TF transforms.
    </p>

    <!-- TECHNICAL DETAILS -->
    <h3 class="section-title reveal">Technical Breakdown</h3>

    <ul class="reveal">
      <li>URDF model with accurate TF tree</li>
      <li>SLAM Toolbox for real-time mapping with loop closure</li>
      <li>Nav2 for autonomous navigation</li>
      <li>Differential-drive odometry</li>
      <li>Costmaps for obstacle detection and inflation</li>
      <li>RViz visualization for mapping, navigation, and debugging</li>
    </ul>

    <!-- OUTCOME -->
    <h3 class="section-title reveal">Outcome</h3>

    <p class="reveal">
      The robot successfully completed autonomous mapping and navigation tasks in a complex multi-room environment.
      This project demonstrates strong capability in <b>ROS2 navigation</b>, <b>SLAM systems</b>, <b>robot modeling</b>,
      and <b>system integration</b>.
    </p>

    <a href="index.html" class="btn ghost reveal">← Back to Projects</a>

  </div>

</body>
</html>
